#!/usr/bin/env python3
"""
Topic-RAGç³»ç»Ÿï¼šåŸºäºå¤šæ¨¡æ€ä¸»é¢˜æ¨¡å‹çš„æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿ

æ­£ç¡®çš„RAGæµç¨‹ï¼š
1. æ¨¡å—ä¸€ï¼šå›¾ç‰‡ç†è§£ + æ–‡æœ¬èåˆ + Topic Modelæ¨ç† + å‘é‡åŒ–
2. æ¨¡å—äºŒï¼šæ£€ç´¢ç›¸å…³æ–¹æ¡ˆ + å¢å¼ºæç¤ºè¯ + ç”Ÿæˆæ–°æ–¹æ¡ˆ
"""

import torch
import numpy as np
import pandas as pd
import joblib
import json
from PIL import Image
import requests
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import normalize
import os
import re
import sys

# æ·»åŠ è·¯å¾„
sys.path.append('..')
sys.path.append('../utils')

from utils.ali_qwen_vl import upload_image_to_imgbb, ali_qwen_vl_image_caption
from utils.doubao_vl import upload_image_to_imgbb, doubao_vl_image_caption
from typing import Tuple, List, Dict, Any
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥æ‚¨çš„æ¨¡å‹
import sys
sys.path.append('..')
from src.topic_model import MultiOmicsETM
from load_separate_models import load_separate_models

IMG_BB_API_KEY = "4961859f178a605de87876a6a75b3a38"
ALI_API_KEY = "sk-8638f33779a8435eb3afe874a9d881d1"
ALI_BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"
DOUBAO_API_KEY = "fc7a6e47-91f5-4ced-9498-75383418e1a5"
DOUBAO_BASE_URL = "https://ark.cn-beijing.volces.com/api/v3"

def _is_url(path):
    return re.match(r'^https?://', path) is not None

class DeepSeekAPI:
    """DeepSeek APIå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.deepseek.com/v1"
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def generate_text(self, prompt: str, model: str = "deepseek-chat") -> str:
        """ç”Ÿæˆæ–‡æœ¬"""
        try:
            url = f"{self.base_url}/chat/completions"
            data = {
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 1500,
                "temperature": 0.7
            }
            
            print(f"æ­£åœ¨è°ƒç”¨DeepSeekæ–‡æœ¬ç”ŸæˆAPIï¼Œæ¨¡å‹: {model}")
            response = requests.post(url, headers=self.headers, json=data, timeout=60)
            
            if response.status_code != 200:
                print(f"APIè°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
                return ""
            
            result = response.json()
            return result["choices"][0]["message"]["content"]
            
        except Exception as e:
            print(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {e}")
            return ""
    
    def analyze_image(self, image_path: str, prompt: str, model: str = "deepseek-vision") -> str:
        """åˆ†æå›¾ç‰‡"""
        try:
            # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(image_path):
                print(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                return "å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨"
            
            # è¯»å–å¹¶ç¼–ç å›¾ç‰‡
            with open(image_path, "rb") as f:
                import base64
                image_data = base64.b64encode(f.read()).decode('utf-8')
            
            url = f"{self.base_url}/chat/completions"
            data = {
                "model": model,
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                        ]
                    }
                ],
                "max_tokens": 1000,
                "temperature": 0.7
            }
            
            print(f"æ­£åœ¨è°ƒç”¨DeepSeekå›¾ç‰‡åˆ†æAPIï¼Œæ¨¡å‹: {model}")
            response = requests.post(url, headers=self.headers, json=data, timeout=60)
            
            if response.status_code != 200:
                print(f"å›¾ç‰‡åˆ†æAPIè°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
                return "å›¾ç‰‡åˆ†æAPIè°ƒç”¨å¤±è´¥"
            
            result = response.json()
            return result["choices"][0]["message"]["content"]
            
        except Exception as e:
            print(f"DeepSeekå›¾ç‰‡åˆ†æå¤±è´¥: {e}")
            return "å›¾ç‰‡åˆ†æå¤±è´¥"

class TopicRAGSystem:
    """Topic-RAGç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self, model_dir='../models', device='cpu', api_key=None):
        """
        åˆå§‹åŒ–Topic-RAGç³»ç»Ÿ
        
        Args:
            model_dir: æ¨¡å‹æ–‡ä»¶ç›®å½•
            device: è®¡ç®—è®¾å¤‡ ('cpu' æˆ– 'cuda')
            api_key: DeepSeek APIå¯†é’¥
        """
        self.device = device
        self.model_dir = model_dir
        
        # åŠ è½½æ¨¡å‹å’Œå¿…è¦ç»„ä»¶
        print("æ­£åœ¨åŠ è½½æ¨¡å‹å’Œç»„ä»¶...")
        self.model, self.vectorizer, self.vocab, self.theta = load_separate_models(model_dir)
        self.model.to(device)
        self.model.eval()
        
        # åŠ è½½åŸå§‹æ•°æ®
        self.df_plans = pd.read_excel('../data/palettes_descriptions.xlsx')
        
        # æ„å»ºæ£€ç´¢æ•°æ®åº“
        self._build_retrieval_database()
        
        # åˆå§‹åŒ–DeepSeek API
        self._init_deepseek(api_key)
        
        print("Topic-RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
    
    def _init_deepseek(self, api_key: str):
        """åˆå§‹åŒ–DeepSeek API"""
        try:
            if api_key:
                self.deepseek = DeepSeekAPI(api_key)
                self.llm_available = True
                print("âœ… DeepSeek APIåˆå§‹åŒ–æˆåŠŸ")
            else:
                print("è­¦å‘Šï¼šæœªæä¾›DeepSeek APIå¯†é’¥ï¼ŒLLMåŠŸèƒ½å°†ä¸å¯ç”¨")
                self.llm_available = False
        except Exception as e:
            print(f"DeepSeek APIåˆå§‹åŒ–å¤±è´¥: {e}")
            self.llm_available = False
    
    def _build_retrieval_database(self):
        """æ„å»ºæ£€ç´¢æ•°æ®åº“"""
        print("æ­£åœ¨æ„å»ºæ£€ç´¢æ•°æ®åº“...")
        
        # ä½¿ç”¨è®­ç»ƒå¥½çš„thetaçŸ©é˜µä½œä¸ºä¸»é¢˜è¡¨ç¤ºï¼ˆæ–‡æœ¬æè¿°çš„è¯åº“ï¼‰
        self.theta_vectors = self.theta.cpu().numpy()
        self.theta_vectors_normalized = normalize(self.theta_vectors, norm='l2', axis=1)
        
        # æ„å»ºé¢œè‰²å‘é‡ï¼ˆä»åŸå§‹æ•°æ®ä¸­æå–ï¼‰
        color_cols = [f'Color_{i}_{c}' for i in range(1, 6) for c in ['R', 'G', 'B']]
        self.color_vectors = self.df_plans[color_cols].values
        self.color_vectors_normalized = normalize(self.color_vectors, norm='l2', axis=1)
        
        # å­˜å‚¨åŸå§‹æ–‡æœ¬æè¿°ï¼ˆè¯åº“ï¼‰
        self.text_descriptions = self.df_plans['description'].values
        
        print(f"æ£€ç´¢æ•°æ®åº“æ„å»ºå®Œæˆï¼š{len(self.theta_vectors)}ä¸ªæ–¹æ¡ˆ")
        print(f"è¯åº“å¤§å°ï¼š{len(self.text_descriptions)}ä¸ªæ–‡æœ¬æè¿°")
    
    def _text_to_bow(self, text: str) -> np.ndarray:
        """
        å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯è¢‹å‘é‡
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            BoWå‘é‡
        """
        # ä½¿ç”¨è®­ç»ƒå¥½çš„TF-IDFå‘é‡åŒ–å™¨
        bow_vector = self.vectorizer.transform([text]).toarray()
        return bow_vector
    
    def _image_understanding(self, image_path):
        """å›¾ç‰‡ç†è§£ï¼šæœ¬åœ°å›¾ç‰‡è‡ªåŠ¨ä¸Šä¼ imgbbå¹¶è°ƒç”¨è±†åŒ…APIï¼Œè¿”å›å›¾ç‰‡æè¿°ï¼Œä¸”æŠŠimgBB URLåŠ è¿›æ–‡æœ¬ä¸­"""
        if _is_url(image_path):
            image_url = image_path
        else:
            image_url = upload_image_to_imgbb(image_path, IMG_BB_API_KEY)
        desc = doubao_vl_image_caption(image_url, DOUBAO_API_KEY, DOUBAO_BASE_URL)
        return f"[imgBB URL]: {image_url}\n{desc}"
    
    def _text_fusion(self, user_text: str, image_analysis: str) -> str:
        """
        èåˆç”¨æˆ·æ–‡æœ¬å’Œå›¾ç‰‡åˆ†æç»“æœ
        
        Args:
            user_text: ç”¨æˆ·æ–‡æœ¬éœ€æ±‚
            image_analysis: å›¾ç‰‡åˆ†æç»“æœ
            
        Returns:
            èåˆåçš„æ–‡æœ¬
        """
        if not self.llm_available:
            # å¦‚æœæ²¡æœ‰LLMï¼Œç®€å•æ‹¼æ¥
            return f"ç”¨æˆ·éœ€æ±‚ï¼š{user_text}\nå›¾ç‰‡åˆ†æï¼š{image_analysis}"
        
        try:
            # æ„å»ºèåˆæç¤ºè¯
            prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„è®¾è®¡æ–¹æ¡ˆæè¿°ï¼š

ç”¨æˆ·éœ€æ±‚ï¼š{user_text}
å›¾ç‰‡åˆ†æï¼š{image_analysis}

è¯·èåˆç”¨æˆ·éœ€æ±‚å’Œå›¾ç‰‡åˆ†æï¼Œç”Ÿæˆä¸€æ®µè¯¦ç»†çš„è®¾è®¡æ–¹æ¡ˆæè¿°ï¼ŒåŒ…æ‹¬ï¼š
1. æ•´ä½“è®¾è®¡é£æ ¼ï¼ˆç»“åˆç”¨æˆ·éœ€æ±‚å’Œå›¾ç‰‡ç‰¹ç‚¹ï¼‰
2. è‰²å½©æ­é…å»ºè®®ï¼ˆåŸºäºå›¾ç‰‡è‰²å½©å’Œç”¨æˆ·åå¥½ï¼‰
3. è®¾è®¡å…ƒç´ ç‰¹ç‚¹ï¼ˆèåˆå›¾ç‰‡å…ƒç´ å’Œç”¨æˆ·éœ€æ±‚ï¼‰
4. é€‚ç”¨åœºæ™¯ï¼ˆæ˜ç¡®å…·ä½“çš„ä½¿ç”¨ç¯å¢ƒï¼‰
5. æƒ…æ„Ÿæ°›å›´ï¼ˆæè¿°è®¾è®¡è¥é€ çš„ç‰¹å®šæƒ…æ„Ÿï¼‰

è¦æ±‚ï¼šè¯­è¨€ä¸“ä¸šï¼Œæè¿°å…·ä½“ï¼Œçªå‡ºè‰²å½©æ­é…ï¼Œä½“ç°ä¸ªæ€§åŒ–ã€‚"""
            
            fused_text = self.deepseek.generate_text(prompt)
            
            if fused_text:
                print(f"æ–‡æœ¬èåˆç»“æœ: {fused_text[:100]}...")
                return fused_text
            else:
                print("æ–‡æœ¬èåˆè¿”å›ç©ºç»“æœï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬")
                return user_text
                
        except Exception as e:
            print(f"æ–‡æœ¬èåˆå¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬")
            return user_text
    
    def _topic_model_inference(self, text_vector: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        ä½¿ç”¨Topic Modelè¿›è¡Œæ¨ç†
        
        Args:
            text_vector: æ–‡æœ¬BoWå‘é‡
            
        Returns:
            (é‡æ„çš„æ–‡æœ¬æ¦‚ç‡, é‡æ„çš„é¢œè‰²æ¦‚ç‡)
        """
        self.model.eval()
        with torch.no_grad():
            # è½¬æ¢ä¸ºtensor
            text_tensor = torch.FloatTensor(text_vector).to(self.device)
            
            # ä½¿ç”¨æ–‡æœ¬ç¼–ç å™¨
            mu_text, logvar_text = self.model.encode_text(text_tensor)
            
            # ç”±äºæ²¡æœ‰é¢œè‰²è¾“å…¥ï¼Œè®¾ç½®é»˜è®¤çš„é¢œè‰²åˆ†å¸ƒï¼ˆé«˜ä¸ç¡®å®šæ€§ï¼‰
            mu_color = torch.zeros_like(mu_text)
            logvar_color = torch.ones_like(logvar_text) * 10
            
            # é«˜æ–¯ä¹˜ç§¯
            mu, logvar = self.model.product_of_gaussians(mu_color, logvar_color, mu_text, logvar_text)
            
            # è·å–ä¸»é¢˜æ¯”ä¾‹
            theta = self.model.get_theta(mu)
            
            # è§£ç å¾—åˆ°é‡æ„ç»“æœ
            recon_color, recon_text = self.model.decode(theta)
            
            return recon_text.cpu().numpy(), recon_color.cpu().numpy()
    
    def module_one_process(self, user_text: str, image_path: str) -> Tuple[np.ndarray, np.ndarray]:
        """
        æ¨¡å—ä¸€ï¼šå›¾ç‰‡ç†è§£ + æ–‡æœ¬èåˆ + Topic Modelæ¨ç† + å‘é‡åŒ–
        
        Args:
            user_text: ç”¨æˆ·æ–‡æœ¬éœ€æ±‚
            image_path: å›¾ç‰‡è·¯å¾„
            
        Returns:
            (é‡æ„çš„æ–‡æœ¬æ¦‚ç‡, é‡æ„çš„é¢œè‰²æ¦‚ç‡)
        """
        print("=== æ¨¡å—ä¸€ï¼šå›¾ç‰‡ç†è§£ + æ–‡æœ¬èåˆ + Topic Modelæ¨ç† ===")
        
        # æ­¥éª¤1.1: å›¾ç‰‡ç†è§£
        print("æ­¥éª¤1.1: æ­£åœ¨ä½¿ç”¨DeepSeek Visionç†è§£å›¾ç‰‡...")
        image_analysis = self._image_understanding(image_path)
        
        # æ­¥éª¤1.2: æ–‡æœ¬èåˆ
        print("æ­¥éª¤1.2: æ­£åœ¨èåˆç”¨æˆ·éœ€æ±‚å’Œå›¾ç‰‡åˆ†æ...")
        fused_text = self._text_fusion(user_text, image_analysis)
        
        # æ­¥éª¤1.3: æ–‡æœ¬å‘é‡åŒ–
        print("æ­¥éª¤1.3: æ­£åœ¨å°†èåˆæ–‡æœ¬å‘é‡åŒ–...")
        bow_vector = self._text_to_bow(fused_text)
        
        # æ­¥éª¤1.4: Topic Modelæ¨ç†
        print("æ­¥éª¤1.4: æ­£åœ¨é€šè¿‡Topic Modelè¿›è¡Œè·¨æ¨¡æ€æ¨ç†...")
        recon_text_prob, recon_color_prob = self._topic_model_inference(bow_vector)
        
        print(f"æ¨ç†å®Œæˆï¼šæ–‡æœ¬æ¦‚ç‡å‘é‡å½¢çŠ¶ {recon_text_prob.shape}, é¢œè‰²æ¦‚ç‡å‘é‡å½¢çŠ¶ {recon_color_prob.shape}")
        
        return recon_text_prob, recon_color_prob
    
    def _retrieve_candidates(self, recon_text_prob: np.ndarray, recon_color_prob: np.ndarray, 
                           top_k: int = 10) -> List[Dict]:
        """
        æ£€ç´¢ç›¸å…³å€™é€‰æ–¹æ¡ˆ - å®ç°åŒé‡ç›¸ä¼¼åº¦è®¡ç®—
        
        Args:
            recon_text_prob: Topic Modelè¾“å‡ºçš„æ–‡æœ¬æ¦‚ç‡çŸ©é˜µ
            recon_color_prob: Topic Modelè¾“å‡ºçš„é¢œè‰²æ¦‚ç‡çŸ©é˜µ
            top_k: æ£€ç´¢æ•°é‡
            
        Returns:
            å€™é€‰æ–¹æ¡ˆåˆ—è¡¨
        """
        print(f"æ­£åœ¨æ£€ç´¢Top-{top_k}ä¸ªç›¸å…³æ–¹æ¡ˆ...")
        
        # æ­¥éª¤1: å°†æ–‡æœ¬æ¦‚ç‡å‘é‡è½¬æ¢ä¸ºä¸»é¢˜å‘é‡
        with torch.no_grad():
            text_tensor = torch.FloatTensor(recon_text_prob).to(self.device)
            mu_text, logvar_text = self.model.encode_text(text_tensor)
            theta_query = self.model.get_theta(mu_text).cpu().numpy()
        
        # æ­¥éª¤2: è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆTopic Modelè¾“å‡ºçš„æ–‡æœ¬çŸ©é˜µä¸è¯åº“çš„ç›¸ä¼¼åº¦ï¼‰
        print("æ­¥éª¤2.1: è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦...")
        theta_query_norm = normalize(theta_query, norm='l2', axis=1)
        text_similarities = cosine_similarity(theta_query_norm, self.theta_vectors_normalized).flatten()
        
        # æ­¥éª¤3: æ ¹æ®æ–‡æœ¬ç›¸ä¼¼åº¦é€‰å‡ºTop-Kä¸ªå€™é€‰æ–¹æ¡ˆ
        print("æ­¥éª¤2.2: æ ¹æ®æ–‡æœ¬ç›¸ä¼¼åº¦é€‰å‡ºå€™é€‰æ–¹æ¡ˆ...")
        top_text_indices = np.argsort(text_similarities)[-top_k*2:][::-1]  # é€‰å‡º2å€æ•°é‡ç”¨äºåç»­ç­›é€‰
        
        print(f"æ–‡æœ¬ç›¸ä¼¼åº¦èŒƒå›´: {text_similarities[top_text_indices].min():.3f} - {text_similarities[top_text_indices].max():.3f}")
        
        # æ­¥éª¤4: è®¡ç®—é¢œè‰²ç›¸ä¼¼åº¦ï¼ˆTopic Modelè¾“å‡ºçš„é¢œè‰²çŸ©é˜µä¸å€™é€‰æ–¹æ¡ˆçš„é¢œè‰²ç›¸ä¼¼åº¦ï¼‰
        print("æ­¥éª¤2.3: è®¡ç®—é¢œè‰²ç›¸ä¼¼åº¦...")
        recon_color_norm = normalize(recon_color_prob, norm='l2', axis=1)
        
        candidates = []
        for idx in top_text_indices:
            # è·å–è¯¥å€™é€‰æ–¹æ¡ˆçš„é¢œè‰²å‘é‡
            candidate_color_vec = self.color_vectors_normalized[idx].reshape(1, -1)
            
            # è®¡ç®—é¢œè‰²ç›¸ä¼¼åº¦
            color_similarity = cosine_similarity(recon_color_norm, candidate_color_vec).item()
            
            # ç»¼åˆå¾—åˆ†ï¼ˆæ–‡æœ¬ç›¸ä¼¼åº¦æƒé‡0.6ï¼Œé¢œè‰²ç›¸ä¼¼åº¦æƒé‡0.4ï¼‰
            combined_score = 0.6 * text_similarities[idx] + 0.4 * color_similarity
            
            candidates.append({
                'index': idx,
                'text_score': text_similarities[idx],
                'color_score': color_similarity,
                'combined_score': combined_score,
                'description': self.df_plans.iloc[idx]['description'],
                'colors': self.df_plans.iloc[idx][[f'Color_{i}_{c}' for i in range(1, 6) for c in ['R', 'G', 'B']]].values.reshape(-1, 3)
            })
        
        # æ­¥éª¤5: æ ¹æ®ç»¼åˆå¾—åˆ†æ’åºï¼Œé€‰å‡ºæœ€ç»ˆçš„Top-Kä¸ªæ–¹æ¡ˆ
        candidates.sort(key=lambda x: x['combined_score'], reverse=True)
        final_candidates = candidates[:top_k]
        
        print(f"æœ€ç»ˆæ£€ç´¢ç»“æœï¼šç»¼åˆå¾—åˆ†èŒƒå›´ {final_candidates[0]['combined_score']:.3f} - {final_candidates[-1]['combined_score']:.3f}")
        
        # æ‰“å°è¯¦ç»†çš„ç›¸ä¼¼åº¦ä¿¡æ¯
        print("\nğŸ“Š æ£€ç´¢è¯¦æƒ…:")
        for i, candidate in enumerate(final_candidates[:3], 1):
            print(f"æ–¹æ¡ˆ{i}: æ–‡æœ¬ç›¸ä¼¼åº¦={candidate['text_score']:.3f}, é¢œè‰²ç›¸ä¼¼åº¦={candidate['color_score']:.3f}, ç»¼åˆå¾—åˆ†={candidate['combined_score']:.3f}")
        
        return final_candidates
    
    def _generate_rag_prompt(self, user_text: str, image_analysis: str, 
                           top_candidates: List[Dict]) -> str:
        """
        æ„å»ºRAGå¢å¼ºæç¤ºè¯
        
        Args:
            user_text: ç”¨æˆ·åŸå§‹éœ€æ±‚
            image_analysis: å›¾ç‰‡åˆ†æç»“æœ
            top_candidates: æ£€ç´¢åˆ°çš„å€™é€‰æ–¹æ¡ˆ
            
        Returns:
            å¢å¼ºåçš„æç¤ºè¯
        """
        # æ„å»ºå‚è€ƒæ–¹æ¡ˆæ–‡æœ¬
        reference_text = "å‚è€ƒè®¾è®¡æ–¹æ¡ˆï¼š\n\n"
        for i, candidate in enumerate(top_candidates[:3], 1):
            colors = candidate['colors']
            color_desc = ""
            for j, color in enumerate(colors, 1):
                color_desc += f"é¢œè‰²{j}: RGB({int(color[0]*255)}, {int(color[1]*255)}, {int(color[2]*255)})\n"
            
            reference_text += f"æ–¹æ¡ˆ{i}ï¼š\næè¿°ï¼š{candidate['description']}\né…è‰²ï¼š\n{color_desc}\n"
        
        # æ„å»ºå¢å¼ºæç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è®¾è®¡ç¾å­¦ä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆä¸€ä¸ªå…¨æ–°çš„ã€ä¸ªæ€§åŒ–çš„è®¾è®¡æ–¹æ¡ˆï¼š

ç”¨æˆ·éœ€æ±‚ï¼š{user_text}

{reference_text}

è¯·åŸºäºä»¥ä¸Šå‚è€ƒæ–¹æ¡ˆï¼Œç»“åˆç”¨æˆ·éœ€æ±‚ï¼Œç”Ÿæˆä¸€ä¸ªå…¨æ–°çš„è®¾è®¡æ–¹æ¡ˆã€‚è¦æ±‚ï¼š

1. è®¾è®¡é£æ ¼ï¼šæ˜ç¡®è¯´æ˜æ•´ä½“è®¾è®¡é£æ ¼ç‰¹ç‚¹ï¼Œè¦ä¸å‚è€ƒæ–¹æ¡ˆæœ‰æ‰€åŒºåˆ«
2. è‰²å½©æ­é…ï¼šæä¾›5ç§é¢œè‰²çš„RGBå€¼ï¼Œå¹¶è¯´æ˜è‰²å½©æ­é…åŸç†å’Œä¸å‚è€ƒæ–¹æ¡ˆçš„åŒºåˆ«
3. è®¾è®¡å…ƒç´ ï¼šæè¿°ä¸»è¦è®¾è®¡å…ƒç´ å’Œå¸ƒå±€ç‰¹ç‚¹ï¼Œä½“ç°åˆ›æ–°æ€§
4. é€‚ç”¨åœºæ™¯ï¼šè¯´æ˜é€‚ç”¨çš„å…·ä½“åœºæ™¯ï¼Œå¯ä»¥æ‰©å±•å‚è€ƒæ–¹æ¡ˆçš„åº”ç”¨èŒƒå›´
5. æƒ…æ„Ÿæ°›å›´ï¼šæè¿°è®¾è®¡è¥é€ çš„æƒ…æ„Ÿæ°›å›´ï¼Œçªå‡ºä¸ªæ€§åŒ–ç‰¹ç‚¹

é‡è¦ï¼šè¯·ç¡®ä¿ç”Ÿæˆçš„è®¾è®¡æ–¹æ¡ˆæ˜¯å…¨æ–°çš„ï¼Œä¸å‚è€ƒæ–¹æ¡ˆæœ‰æ˜æ˜¾åŒºåˆ«ï¼ŒåŒæ—¶æ»¡è¶³ç”¨æˆ·éœ€æ±‚ã€‚
è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œè¯­è¨€ä¸“ä¸šä¼˜ç¾ï¼Œçªå‡ºåˆ›æ–°æ€§å’Œä¸ªæ€§åŒ–ç‰¹ç‚¹ã€‚"""
        
        return prompt
    
    def module_two_process(self, recon_text_prob: np.ndarray, recon_color_prob: np.ndarray, 
                          user_text: str, image_analysis: str, top_k: int = 10) -> Dict[str, Any]:
        """
        æ¨¡å—äºŒï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆ
        
        Args:
            recon_text_prob: é‡æ„çš„æ–‡æœ¬æ¦‚ç‡
            recon_color_prob: é‡æ„çš„é¢œè‰²æ¦‚ç‡
            user_text: ç”¨æˆ·åŸå§‹éœ€æ±‚
            image_analysis: å›¾ç‰‡åˆ†æç»“æœ
            top_k: æ£€ç´¢å€™é€‰æ•°é‡
            
        Returns:
            ç”Ÿæˆçš„æ–°æ–¹æ¡ˆ
        """
        print("=== æ¨¡å—äºŒï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆ ===")
        
        # æ­¥éª¤2.1: æ£€ç´¢ç›¸å…³å€™é€‰æ–¹æ¡ˆ
        print("æ­¥éª¤2.1: æ­£åœ¨æ£€ç´¢ç›¸å…³å€™é€‰æ–¹æ¡ˆ...")
        candidates = self._retrieve_candidates(recon_text_prob, recon_color_prob, top_k)
        
        # æ­¥éª¤2.2: æ„å»ºRAGå¢å¼ºæç¤ºè¯
        print("æ­¥éª¤2.2: æ­£åœ¨æ„å»ºRAGå¢å¼ºæç¤ºè¯...")
        rag_prompt = self._generate_rag_prompt(user_text, image_analysis, candidates)
        
        # æ­¥éª¤2.3: ç”Ÿæˆæ–°æ–¹æ¡ˆ
        print("æ­¥éª¤2.3: æ­£åœ¨ç”Ÿæˆæ–°æ–¹æ¡ˆ...")
        if self.llm_available:
            new_plan = self.deepseek.generate_text(rag_prompt)
        else:
            new_plan = "LLMä¸å¯ç”¨ï¼Œæ— æ³•ç”Ÿæˆæ–°æ–¹æ¡ˆ"
        
        return {
            'new_plan': new_plan,
            'candidates': candidates[:3],  # è¿”å›å‰3ä¸ªå€™é€‰
            'rag_prompt': rag_prompt
        }
    
    def run_full_pipeline(self, user_text: str, image_path: str, top_k: int = 10) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„Topic-RAGæµç¨‹
        
        Args:
            user_text: ç”¨æˆ·æ–‡æœ¬éœ€æ±‚
            image_path: å›¾ç‰‡è·¯å¾„
            top_k: æ£€ç´¢å€™é€‰æ•°é‡
            
        Returns:
            å®Œæ•´çš„å¤„ç†ç»“æœ
        """
        print("ğŸš€ å¯åŠ¨Topic-RAGç³»ç»Ÿ...")
        print(f"ç”¨æˆ·éœ€æ±‚: {user_text}")
        print(f"å›¾ç‰‡è·¯å¾„: {image_path}")
        
        # æ¨¡å—ä¸€ï¼šå›¾ç‰‡ç†è§£ + æ–‡æœ¬èåˆ + Topic Modelæ¨ç†
        recon_text_prob, recon_color_prob = self.module_one_process(user_text, image_path)
        
        # è·å–å›¾ç‰‡åˆ†æç»“æœï¼ˆç”¨äºæ¨¡å—äºŒï¼‰
        image_analysis = self._image_understanding(image_path)
        
        # æ¨¡å—äºŒï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆ
        result = self.module_two_process(recon_text_prob, recon_color_prob, user_text, image_analysis, top_k)
        
        print("\n" + "="*50)
        print("âœ¨ ç”Ÿæˆçš„æ–°è®¾è®¡æ–¹æ¡ˆ âœ¨")
        print("="*50)
        print(result['new_plan'])
        print("="*50)
        
        return result

def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºç³»ç»Ÿä½¿ç”¨"""
    
    # ä½¿ç”¨æ‚¨æä¾›çš„APIå¯†é’¥
    api_key = "sk-3c4ba59c8b094106995821395c7bc60e"
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    system = TopicRAGSystem(device='cpu', api_key=api_key)
    
    # ç¤ºä¾‹ä½¿ç”¨
    user_text = "æˆ‘æƒ³è¦ä¸€ä¸ªç°ä»£ç®€çº¦é£æ ¼çš„é…è‰²æ–¹æ¡ˆï¼Œé€‚åˆåŠå…¬ç¯å¢ƒ"
    image_path = "test_image.jpg"  # æ›¿æ¢ä¸ºå®é™…å›¾ç‰‡è·¯å¾„
    
    # è¿è¡Œå®Œæ•´æµç¨‹
    result = system.run_full_pipeline(user_text, image_path)
    
    # æ‰“å°æ£€ç´¢è¯¦æƒ…
    print("\nğŸ“Š æ£€ç´¢åˆ°çš„å‚è€ƒæ–¹æ¡ˆ:")
    for i, candidate in enumerate(result['candidates'], 1):
        print(f"{i}. ç»¼åˆå¾—åˆ†: {candidate['combined_score']:.3f}")
        print(f"   æè¿°: {candidate['description'][:100]}...")

if __name__ == "__main__":
    main() 