#!/usr/bin/env python3
"""
Streamlit Webç•Œé¢ - RAGé…è‰²æ–¹æ¡ˆç”Ÿæˆç³»ç»Ÿ
åŸºäºæˆåŠŸçš„simple_pipeline.pyæ„å»ºç”¨æˆ·å‹å¥½çš„Webç•Œé¢
"""

import streamlit as st
import os
import sys
import torch
import numpy as np
import json
import pickle
import base64
from typing import Dict, Any, List, Tuple
from sklearn.metrics.pairwise import cosine_similarity
from PIL import Image
import io
from datetime import datetime

# æ·»åŠ è·¯å¾„
sys.path.append('.')
sys.path.append('..')
sys.path.append('/root/autodl-tmp/AETM')
sys.path.append('/root/autodl-tmp/AETM/src')

# APIé…ç½®
DOUBAO_API_KEY = "fc7a6e47-91f5-4ced-9498-75383418e1a5"
DEEPSEEK_API_KEY = "sk-3c4ba59c8b094106995821395c7bc60e"

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ColorRAG - æ™ºèƒ½é…è‰²è®¾è®¡å¹³å°",
    page_icon="ğŸ¨",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# å•†ä¸šåŒ–CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        text-align: center;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-size: 3rem;
        font-weight: 800;
        margin-bottom: 1rem;
        letter-spacing: -1px;
    }
    .subtitle {
        text-align: center;
        color: #666;
        font-size: 1.2rem;
        margin-bottom: 3rem;
        font-weight: 300;
    }
    .feature-card {
        background: white;
        border-radius: 15px;
        padding: 2rem;
        margin: 1rem 0;
        box-shadow: 0 8px 25px rgba(0,0,0,0.1);
        border: 1px solid #f0f0f0;
        transition: transform 0.3s ease;
    }
    .feature-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 12px 35px rgba(0,0,0,0.15);
    }
    .step-number {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        width: 40px;
        height: 40px;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        font-weight: bold;
        font-size: 1.2rem;
        margin-bottom: 1rem;
    }
    .result-card {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        border-radius: 20px;
        padding: 2rem;
        margin: 2rem 0;
        box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        border: none;
    }
    .color-palette {
        background: white;
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 5px 15px rgba(0,0,0,0.08);
    }
    .generate-btn {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 50px;
        padding: 1rem 3rem;
        font-size: 1.1rem;
        font-weight: 600;
        cursor: pointer;
        transition: all 0.3s ease;
        box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
    }
    .generate-btn:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(102, 126, 234, 0.6);
    }
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def load_models():
    """åŠ è½½æ‰€æœ‰æ¨¡å‹å’Œæ•°æ®"""
    try:
        # å¯¼å…¥æ¨¡å‹ç±»
        from topic_model import MultiOmicsETM
        
        # åŠ è½½æ¨¡å‹æ¶æ„
        with open('/root/autodl-tmp/AETM/models/model_architecture.json', 'r') as f:
            architecture = json.load(f)
        
        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        model = MultiOmicsETM(
            num_topics=architecture['num_topics'],
            color_dim=architecture['color_dim'],
            text_dim=architecture['text_dim'],
            embedding_dim=architecture['embedding_dim'],
            hidden_dim=architecture['hidden_dim'],
            dropout=architecture['dropout']
        )
        
        # åŠ è½½è§£ç å™¨æƒé‡
        decoder_state = torch.load('/root/autodl-tmp/AETM/models/best_decoder.pth', map_location='cpu')
        model.alpha.data = decoder_state['alpha']
        model.rho_color.data = decoder_state['rho_color']
        model.rho_text.data = decoder_state['rho_text']
        
        # åŠ è½½é¢„è®­ç»ƒçš„theta
        theta = torch.load('/root/autodl-tmp/AETM/models/best_theta.pt', map_location='cpu')
        
        # åŠ è½½çŸ¥è¯†åº“
        with open('/root/autodl-tmp/AETM/rag/langchain/knowledge_base.pkl', 'rb') as f:
            knowledge_base = pickle.load(f)
        
        model.eval()
        return model, theta, knowledge_base, architecture
        
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        return None, None, None, None

def image_understanding(image_file, user_text: str) -> str:
    """å›¾ç‰‡ç†è§£ä¸æ–‡æœ¬èåˆ"""
    try:
        from openai import OpenAI

        # é™é»˜å¤„ç†å›¾ç‰‡
        image_file.seek(0)
        image = Image.open(image_file)

        # è½¬æ¢ä¸ºRGBæ ¼å¼
        if image.mode != 'RGB':
            image = image.convert('RGB')

        # è°ƒæ•´å›¾ç‰‡å¤§å°ï¼ˆé¿å…è¿‡å¤§ï¼‰
        max_size = (800, 600)
        if image.size[0] > max_size[0] or image.size[1] > max_size[1]:
            image.thumbnail(max_size, Image.Resampling.LANCZOS)

        # ç¼–ç å›¾ç‰‡
        img_buffer = io.BytesIO()
        image.save(img_buffer, format='JPEG', quality=85, optimize=True)
        img_buffer.seek(0)
        image_data = img_buffer.getvalue()
        image_base64 = base64.b64encode(image_data).decode('utf-8')

        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ["ARK_API_KEY"] = DOUBAO_API_KEY

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        client = OpenAI(
            base_url="https://ark.cn-beijing.volces.com/api/v3",
            api_key=DOUBAO_API_KEY,
        )

        response = client.chat.completions.create(
            model="doubao-1-5-thinking-vision-pro-250428",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}"
                            },
                        },
                        {
                            "type": "text",
                            "text": "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š1.ä¸»è¦ç‰©ä½“å’Œåœºæ™¯ 2.è‰²å½©æ­é…å’Œé£æ ¼ç‰¹ç‚¹ 3.æ•´ä½“æ°›å›´å’Œæ„Ÿå— 4.å¯èƒ½çš„è®¾è®¡é£æ ¼ã€‚è¯·ç”¨ç®€æ´æ˜äº†çš„è¯­è¨€æè¿°ï¼Œé‡ç‚¹å…³æ³¨è‰²å½©å’Œè®¾è®¡ç›¸å…³çš„ä¿¡æ¯ã€‚"
                        },
                    ],
                }
            ],
            timeout=30
        )

        image_description = response.choices[0].message.content

    except Exception as e:
        error_msg = str(e)
        st.error(f"âŒ è±†åŒ…APIè°ƒç”¨å¤±è´¥: {error_msg}")

        # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
        if "timeout" in error_msg.lower():
            st.warning("â° APIè°ƒç”¨è¶…æ—¶ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜")
        elif "401" in error_msg or "unauthorized" in error_msg.lower():
            st.warning("ğŸ”‘ APIå¯†é’¥å¯èƒ½æ— æ•ˆæˆ–å·²è¿‡æœŸ")
        elif "429" in error_msg or "rate limit" in error_msg.lower():
            st.warning("ğŸš« APIè°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œè¯·ç¨åé‡è¯•")
        else:
            st.warning("ğŸ”§ å…¶ä»–APIé”™è¯¯ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæè¿°ç»§ç»­")

        # ä½¿ç”¨æ¨¡æ‹Ÿæè¿°
        image_description = "è¿™æ˜¯ä¸€å¼ ç°ä»£è®¾è®¡å›¾ç‰‡ï¼Œè‰²å½©æ­é…ç®€æ´ä¼˜é›…ï¼Œæ•´ä½“é£æ ¼ç°ä»£ç®€çº¦ï¼Œå…·æœ‰è‰¯å¥½çš„è§†è§‰å±‚æ¬¡å’Œè‰²å½©å¹³è¡¡ã€‚"
        # é™é»˜åˆ‡æ¢åˆ°æ¨¡æ‹Ÿå›¾ç‰‡æè¿°æ¨¡å¼

    # èåˆæ–‡æœ¬
    fused_text = f"ç”¨æˆ·éœ€æ±‚: {user_text}\nå›¾ç‰‡å†…å®¹: {image_description}"
    return fused_text, image_description

def topic_model_inference(model, theta, fused_text: str):
    """Topic Modelæ¨ç†ç”Ÿæˆæ–‡æœ¬å’Œé¢œè‰²çŸ©é˜µ"""
    try:
        words = fused_text.lower().split()
        text_keywords = ['ç°ä»£', 'ç®€çº¦', 'åŠå…¬', 'ä¸“ä¸š', 'æ¸©é¦¨', 'æç®€', 'å‡ ä½•', 'è“', 'ç°', 'ç±³']
        text_score = sum(1 for word in words for keyword in text_keywords if keyword in word)
        
        if text_score > 0:
            selected_idx = min(theta.shape[0] // 2 + text_score * 100, theta.shape[0] - 1)
        else:
            selected_idx = theta.shape[0] // 2
            
        selected_theta = theta[selected_idx:selected_idx+1]
        
        with torch.no_grad():
            # ç”Ÿæˆä¸»é¢˜åµŒå…¥
            topic_embedding = torch.matmul(selected_theta, model.alpha.data)
            # ç”Ÿæˆæ–‡æœ¬çŸ©é˜µå’Œé¢œè‰²çŸ©é˜µ
            text_matrix = torch.matmul(topic_embedding, model.rho_text.data)
            color_matrix = torch.matmul(topic_embedding, model.rho_color.data)

        return text_matrix, color_matrix, selected_idx
        
    except Exception as e:
        st.error(f"Topic Modelæ¨ç†å¤±è´¥: {str(e)}")
        return None, None, None

def similarity_retrieval(text_matrix, color_matrix, knowledge_base, text_top_k=10, final_top_k=3):
    """ä¸¤é˜¶æ®µç›¸ä¼¼åº¦æ£€ç´¢"""
    try:
        kb_data = knowledge_base['data']
        descriptions = kb_data['descriptions']
        color_vectors = kb_data['knowledge_color_vectors']
        text_vectors = kb_data['knowledge_text_vectors']
        
        # ç¬¬ä¸€é˜¶æ®µï¼šæ–‡æœ¬ç›¸ä¼¼åº¦
        query_text = text_matrix.detach().cpu().numpy()
        text_similarities = cosine_similarity(query_text, text_vectors)[0]
        # å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
        text_similarities = (text_similarities + 1) / 2
        text_top_indices = np.argsort(text_similarities)[-text_top_k:][::-1]

        # ç¬¬äºŒé˜¶æ®µï¼šé¢œè‰²ç›¸ä¼¼åº¦
        candidate_color_vectors = color_vectors[text_top_indices]
        query_color = color_matrix.detach().cpu().numpy()

        # æ£€æŸ¥ç»´åº¦åŒ¹é…
        if query_color.shape[1] != candidate_color_vectors.shape[1]:
            # è°ƒæ•´ç»´åº¦
            min_dim = min(query_color.shape[1], candidate_color_vectors.shape[1])
            query_color = query_color[:, :min_dim]
            candidate_color_vectors = candidate_color_vectors[:, :min_dim]

        candidate_color_similarities = cosine_similarity(query_color, candidate_color_vectors)[0]
        # å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
        candidate_color_similarities = (candidate_color_similarities + 1) / 2
        color_top_indices = np.argsort(candidate_color_similarities)[-final_top_k:][::-1]
        
        # æ„å»ºæœ€ç»ˆç»“æœ
        final_results = []
        for i, color_idx in enumerate(color_top_indices):
            original_idx = text_top_indices[color_idx]
            result = {
                'rank': i + 1,
                'index': int(original_idx),
                'text_similarity': float(text_similarities[original_idx]),
                'color_similarity': float(candidate_color_similarities[color_idx]),
                'description': descriptions[original_idx],
                'color_vector': color_vectors[original_idx].tolist()
            }
            final_results.append(result)
        
        return final_results, text_similarities.max(), candidate_color_similarities.max()
        
    except Exception as e:
        st.error(f"ç›¸ä¼¼åº¦æ£€ç´¢å¤±è´¥: {str(e)}")
        return [], 0, 0

def deepseek_generation_multiple(text_matrix, color_matrix, top_results: List[Dict], original_text: str, image_description: str) -> List[str]:
    """DeepSeekåŸºäº3ä¸ªçŸ¥è¯†åº“æ–¹æ¡ˆåˆ†åˆ«ç”Ÿæˆ3ä¸ªæ–°æ–¹æ¡ˆ"""
    try:
        generated_plans = []

        # ä¸ºæ¯ä¸ªçŸ¥è¯†åº“æ–¹æ¡ˆç”Ÿæˆä¸€ä¸ªæ–°çš„é…è‰²æ–¹æ¡ˆ
        for i, result in enumerate(top_results[:3]):

            # æ„å»ºå•ä¸ªæ–¹æ¡ˆçš„è¯¦ç»†ä¿¡æ¯
            color_vector = result['color_vector']
            kb_colors = []
            if len(color_vector) >= 15:
                for j in range(5):
                    start_idx = j * 3
                    if start_idx + 2 < len(color_vector):
                        r = int(np.clip(color_vector[start_idx] * 255, 0, 255))
                        g = int(np.clip(color_vector[start_idx + 1] * 255, 0, 255))
                        b = int(np.clip(color_vector[start_idx + 2] * 255, 0, 255))
                        kb_colors.append(f"RGB({r}, {g}, {b})")

            # ä¸ºæ¯ä¸ªæ–¹æ¡ˆæ„å»ºä¸“é—¨çš„æç¤ºè¯
            individual_prompt = f"""ä½ æ˜¯ä¸€ä½é¡¶çº§çš„è‰²å½©è®¾è®¡å¤§å¸ˆã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œåˆ›ä½œä¸€ä¸ªå…¨æ–°çš„é…è‰²æ–¹æ¡ˆã€‚

**ç”¨æˆ·éœ€æ±‚:**
{original_text}

**å›¾ç‰‡åˆ†æ:**
{image_description}

**å‚è€ƒæ–¹æ¡ˆ** (æ–‡æœ¬ç›¸ä¼¼åº¦: {result['text_similarity']:.3f}, é¢œè‰²ç›¸ä¼¼åº¦: {result['color_similarity']:.3f}):
æ–¹æ¡ˆæè¿°: {result['description']}
å‚è€ƒé¢œè‰²: {', '.join(kb_colors) if kb_colors else 'é¢œè‰²æ•°æ®ä¸å®Œæ•´'}

**åˆ›ä½œè¦æ±‚:**
è¯·ä»¥è¿™ä¸ªå‚è€ƒæ–¹æ¡ˆä¸ºçµæ„Ÿï¼Œç»“åˆå›¾ç‰‡é£æ ¼å’Œç”¨æˆ·éœ€æ±‚ï¼Œåˆ›ä½œä¸€ä¸ªå…¨æ–°çš„é…è‰²æ–¹æ¡ˆã€‚è¦æ±‚ä¸å‚è€ƒæ–¹æ¡ˆæœ‰æ‰€åŒºåˆ«ï¼Œä½“ç°åˆ›æ–°æ€§ã€‚

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

**è®¾è®¡ç†å¿µ**
[ç®€æ´æè¿°è®¾è®¡æ€è·¯ï¼Œè¯´æ˜å¦‚ä½•åœ¨å‚è€ƒæ–¹æ¡ˆåŸºç¡€ä¸Šåˆ›æ–°]

**é…è‰²æ–¹æ¡ˆ**
é¢œè‰²åç§° - RGB(r, g, b)
é¢œè‰²åç§° - RGB(r, g, b)
é¢œè‰²åç§° - RGB(r, g, b)
é¢œè‰²åç§° - RGB(r, g, b)
é¢œè‰²åç§° - RGB(r, g, b)

**åº”ç”¨å»ºè®®**
[è¯´æ˜é€‚ç”¨åœºæ™¯å’Œæ­é…å»ºè®®]

æ³¨æ„ï¼šè¯·ç¡®ä¿æ–¹æ¡ˆæ—¢æœ‰åˆ›æ–°æ€§åˆå®ç”¨ï¼Œä¸å‚è€ƒæ–¹æ¡ˆç›¸å…³ä½†ä¸é›·åŒã€‚"""
        
            # è°ƒç”¨DeepSeek APIä¸ºå½“å‰æ–¹æ¡ˆç”Ÿæˆæ–°é…è‰²
            import requests
            import time

            headers = {
                "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
                "Content-Type": "application/json"
            }

            payload = {
                "model": "deepseek-chat",
                "messages": [{"role": "user", "content": individual_prompt}],
                "temperature": 0.7 + i * 0.1,  # æ¯ä¸ªæ–¹æ¡ˆä½¿ç”¨ä¸åŒçš„æ¸©åº¦å¢åŠ å¤šæ ·æ€§
                "max_tokens": 1000
            }

            # ä¸ºæ¯ä¸ªæ–¹æ¡ˆé‡è¯•
            max_retries = 2  # å‡å°‘é‡è¯•æ¬¡æ•°ï¼Œå› ä¸ºè¦ç”Ÿæˆ3ä¸ªæ–¹æ¡ˆ
            plan_generated = False

            for attempt in range(max_retries):
                try:
                    response = requests.post(
                        "https://api.deepseek.com/v1/chat/completions",
                        headers=headers,
                        json=payload,
                        timeout=45  # ç¨å¾®å‡å°‘è¶…æ—¶æ—¶é—´
                    )

                    if response.status_code == 200:
                        result = response.json()
                        generated_plan = result["choices"][0]["message"]["content"]
                        generated_plans.append({
                            "title": f"æ–¹æ¡ˆ{i+1}ï¼šåŸºäºçŸ¥è¯†åº“æ–¹æ¡ˆ{i+1}çš„åˆ›æ–°è®¾è®¡",
                            "content": generated_plan,
                            "reference_similarity": result.get('text_similarity', 0) + result.get('color_similarity', 0)
                        })
                        # æ–¹æ¡ˆç”ŸæˆæˆåŠŸï¼Œç»§ç»­å¤„ç†
                        plan_generated = True
                        break
                    else:
                        if attempt < max_retries - 1:
                            time.sleep(1)
                            continue

                except (requests.exceptions.Timeout, requests.exceptions.ConnectionError):
                    if attempt < max_retries - 1:
                        time.sleep(2)
                        continue

            # å¦‚æœAPIå¤±è´¥ï¼Œç”Ÿæˆå¤‡ç”¨æ–¹æ¡ˆ
            if not plan_generated:
                st.warning(f"âš ï¸ æ–¹æ¡ˆ{i+1} APIå¤±è´¥ï¼Œç”Ÿæˆå¤‡ç”¨æ–¹æ¡ˆ")
                fallback = generate_single_fallback_plan(result, original_text, image_description, i+1)
                generated_plans.append({
                    "title": f"æ–¹æ¡ˆ{i+1}ï¼šåŸºäºçŸ¥è¯†åº“æ–¹æ¡ˆ{i+1}çš„å¤‡ç”¨è®¾è®¡",
                    "content": fallback,
                    "reference_similarity": result.get('text_similarity', 0) + result.get('color_similarity', 0)
                })

        return generated_plans

    except Exception as e:
        st.error(f"DeepSeekç”Ÿæˆå¤±è´¥: {str(e)}")
        # ç”Ÿæˆ3ä¸ªå¤‡ç”¨æ–¹æ¡ˆ
        fallback_plans = []
        for i, result in enumerate(top_results[:3]):
            fallback = generate_single_fallback_plan(result, original_text, image_description, i+1)
            fallback_plans.append({
                "title": f"æ–¹æ¡ˆ{i+1}ï¼šå¤‡ç”¨è®¾è®¡æ–¹æ¡ˆ",
                "content": fallback,
                "reference_similarity": result.get('text_similarity', 0) + result.get('color_similarity', 0)
            })
        return fallback_plans

def generate_single_fallback_plan(result: Dict, original_text: str, image_description: str, plan_num: int) -> str:
    """ä¸ºå•ä¸ªçŸ¥è¯†åº“æ–¹æ¡ˆç”Ÿæˆå¤‡ç”¨é…è‰²æ–¹æ¡ˆ"""
    try:
        # ä»çŸ¥è¯†åº“æ–¹æ¡ˆæå–é¢œè‰²
        color_vector = result['color_vector']
        fallback_colors = []

        if len(color_vector) >= 15:
            for i in range(5):
                start_idx = i * 3
                if start_idx + 2 < len(color_vector):
                    # åœ¨åŸé¢œè‰²åŸºç¡€ä¸Šè¿›è¡Œå¾®è°ƒï¼Œå¢åŠ å˜åŒ–
                    r = int(np.clip(color_vector[start_idx] * 255 + (plan_num * 10), 0, 255))
                    g = int(np.clip(color_vector[start_idx + 1] * 255 + (plan_num * 15), 0, 255))
                    b = int(np.clip(color_vector[start_idx + 2] * 255 + (plan_num * 5), 0, 255))

                    color_names = ["ä¸»è‰²è°ƒ", "è¾…åŠ©è‰²", "ç‚¹ç¼€è‰²", "èƒŒæ™¯è‰²", "å¼ºè°ƒè‰²"]
                    fallback_colors.append(f"{color_names[i]} - RGB({r}, {g}, {b})")

        # ç”Ÿæˆå¤‡ç”¨æ–¹æ¡ˆæ–‡æœ¬
        style_variations = [
            "ç°ä»£ç®€çº¦é£æ ¼çš„åˆ›æ–°æ¼”ç»",
            "ç»å…¸ä¸ç°ä»£çš„å®Œç¾èåˆ",
            "è‡ªç„¶çµæ„Ÿçš„è‰²å½©è¡¨è¾¾"
        ]

        fallback_plan = f"""**è®¾è®¡ç†å¿µ**
åŸºäºçŸ¥è¯†åº“ä¼˜ç§€æ–¹æ¡ˆçš„{style_variations[(plan_num-1) % 3]}ï¼Œç»“åˆ{image_description.split('ï¼Œ')[0] if 'ï¼Œ' in image_description else 'å›¾ç‰‡ç‰¹ç‚¹'}ï¼Œåˆ›é€ å‡ºæ—¢ç¬¦åˆ{original_text.split('ï¼Œ')[0] if 'ï¼Œ' in original_text else 'ç”¨æˆ·éœ€æ±‚'}åˆå…·æœ‰ç‹¬ç‰¹ä¸ªæ€§çš„é…è‰²æ–¹æ¡ˆã€‚

**é…è‰²æ–¹æ¡ˆ**
{chr(10).join(fallback_colors)}

**åº”ç”¨å»ºè®®**
æ­¤æ–¹æ¡ˆé€‚ç”¨äº{original_text}çš„åº”ç”¨åœºæ™¯ï¼Œè‰²å½©å±‚æ¬¡ä¸°å¯Œï¼Œæ—¢ä¿æŒæ•´ä½“å’Œè°åˆçªå‡ºé‡ç‚¹åŒºåŸŸï¼Œå»ºè®®åœ¨å®é™…åº”ç”¨ä¸­æ ¹æ®å…·ä½“ç¯å¢ƒè¿›è¡Œå¾®è°ƒã€‚"""

        return fallback_plan

    except Exception as e:
        return f"å¤‡ç”¨æ–¹æ¡ˆ{plan_num}ç”Ÿæˆå¤±è´¥: {str(e)}"

def generate_fallback_plan(top_results: List[Dict], original_text: str, image_description: str) -> str:
    """ç”Ÿæˆå¤‡ç”¨é…è‰²æ–¹æ¡ˆï¼ˆå½“DeepSeek APIå¤±è´¥æ—¶ï¼‰"""
    try:
        # é™é»˜ç”Ÿæˆå¤‡ç”¨é…è‰²æ–¹æ¡ˆ

        # åŸºäºçŸ¥è¯†åº“æœ€ä½³æ–¹æ¡ˆç”Ÿæˆå¤‡ç”¨æ–¹æ¡ˆ
        if top_results and len(top_results) > 0:
            best_result = top_results[0]

            # ä»æœ€ä½³æ–¹æ¡ˆæå–é¢œè‰²
            color_vector = best_result['color_vector']
            fallback_colors = []

            if len(color_vector) >= 15:
                for i in range(5):
                    start_idx = i * 3
                    if start_idx + 2 < len(color_vector):
                        r = int(np.clip(color_vector[start_idx] * 255, 0, 255))
                        g = int(np.clip(color_vector[start_idx + 1] * 255, 0, 255))
                        b = int(np.clip(color_vector[start_idx + 2] * 255, 0, 255))

                        # æ ¹æ®ä½ç½®ç»™é¢œè‰²å‘½å
                        color_names = ["ä¸»è‰²è°ƒ", "è¾…åŠ©è‰²", "ç‚¹ç¼€è‰²", "èƒŒæ™¯è‰²", "å¼ºè°ƒè‰²"]
                        fallback_colors.append(f"{color_names[i]} - RGB({r}, {g}, {b})")

            # ç”Ÿæˆå¤‡ç”¨æ–¹æ¡ˆæ–‡æœ¬
            fallback_plan = f"""**è®¾è®¡ç†å¿µ**
åŸºäºå›¾ç‰‡åˆ†æå’ŒçŸ¥è¯†åº“æœ€ä½³åŒ¹é…æ–¹æ¡ˆï¼Œè¿™æ˜¯ä¸€ä¸ªèåˆäº†{image_description.split('ï¼Œ')[0] if 'ï¼Œ' in image_description else 'ç°ä»£è®¾è®¡'}ç‰¹ç‚¹çš„é…è‰²æ–¹æ¡ˆã€‚æ•´ä½“è‰²è°ƒå’Œè°ç»Ÿä¸€ï¼Œæ—¢æ»¡è¶³ç”¨æˆ·çš„{original_text.split('ï¼Œ')[0] if 'ï¼Œ' in original_text else 'è®¾è®¡éœ€æ±‚'}ï¼Œåˆä½“ç°äº†ä¸“ä¸šçš„è‰²å½©æ­é…åŸåˆ™ã€‚

**é…è‰²æ–¹æ¡ˆ**
{chr(10).join(fallback_colors)}

**åº”ç”¨å»ºè®®**
æ­¤é…è‰²æ–¹æ¡ˆé€‚ç”¨äº{original_text}çš„åœºæ™¯ï¼Œå»ºè®®ä¸»è‰²è°ƒç”¨äºå¤§é¢ç§¯åŒºåŸŸï¼Œè¾…åŠ©è‰²ç”¨äºåŠŸèƒ½åŒºåŸŸï¼Œç‚¹ç¼€è‰²ç”¨äºé‡è¦å…ƒç´ çªå‡ºï¼ŒèƒŒæ™¯è‰²ä¿æŒç©ºé—´çš„æ•´æ´æ„Ÿï¼Œå¼ºè°ƒè‰²ç”¨äºå…³é”®ä¿¡æ¯çš„è§†è§‰å¼•å¯¼ã€‚æ•´ä½“æ­é…æ—¢ä¿æŒè§†è§‰èˆ’é€‚åº¦ï¼Œåˆå…·æœ‰è‰¯å¥½çš„åŠŸèƒ½æ€§ã€‚"""

            # å¤‡ç”¨é…è‰²æ–¹æ¡ˆç”Ÿæˆå®Œæˆ
            return fallback_plan

        else:
            # å¦‚æœè¿çŸ¥è¯†åº“ç»“æœéƒ½æ²¡æœ‰ï¼Œç”Ÿæˆé€šç”¨æ–¹æ¡ˆ
            generic_plan = f"""**è®¾è®¡ç†å¿µ**
åŸºäº{image_description}çš„è§†è§‰ç‰¹ç‚¹ï¼Œç»“åˆ{original_text}çš„éœ€æ±‚ï¼Œé‡‡ç”¨ç»å…¸çš„é…è‰²ç†è®ºï¼Œåˆ›é€ å‡ºæ—¢å®ç”¨åˆç¾è§‚çš„è‰²å½©æ–¹æ¡ˆã€‚

**é…è‰²æ–¹æ¡ˆ**
ä¸»è‰²è°ƒ - RGB(70, 130, 180)
è¾…åŠ©è‰² - RGB(245, 245, 245)
ç‚¹ç¼€è‰² - RGB(255, 165, 0)
èƒŒæ™¯è‰² - RGB(248, 248, 255)
å¼ºè°ƒè‰² - RGB(220, 20, 60)

**åº”ç”¨å»ºè®®**
è¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„é…è‰²æ–¹æ¡ˆï¼Œé€‚åˆå¤šç§åº”ç”¨åœºæ™¯ã€‚å»ºè®®æ ¹æ®å…·ä½“éœ€æ±‚è¿›è¡Œå¾®è°ƒã€‚"""

            st.info("âœ… é€šç”¨é…è‰²æ–¹æ¡ˆç”Ÿæˆå®Œæˆ")
            return generic_plan

    except Exception as e:
        st.error(f"å¤‡ç”¨æ–¹æ¡ˆç”Ÿæˆä¹Ÿå¤±è´¥äº†: {str(e)}")
        return "ç³»ç»Ÿæš‚æ—¶æ— æ³•ç”Ÿæˆé…è‰²æ–¹æ¡ˆï¼Œè¯·ç¨åé‡è¯•ã€‚"

def display_color_palette(colors_rgb: List[str], title: str):
    """æ˜¾ç¤ºé¢œè‰²è°ƒè‰²æ¿"""
    st.subheader(title)

    if not colors_rgb:
        st.warning("æœªæ‰¾åˆ°é¢œè‰²ä¿¡æ¯")
        return

    # ä½¿ç”¨Streamlitçš„åˆ—å¸ƒå±€æ˜¾ç¤ºé¢œè‰²
    cols = st.columns(len(colors_rgb))

    for i, color_str in enumerate(colors_rgb):
        with cols[i]:
            try:
                # æå–RGBå€¼
                rgb_values = color_str.replace('RGB(', '').replace(')', '').split(', ')
                r, g, b = map(int, rgb_values)
                hex_color = f"#{r:02x}{g:02x}{b:02x}"

                # åˆ›å»ºé¢œè‰²å— - ä¸æ˜¾ç¤ºç¼–å·
                st.markdown(f"""
                <div style='text-align: center;'>
                    <div style='
                        width: 100px;
                        height: 100px;
                        background-color: {hex_color};
                        border-radius: 10px;
                        border: 2px solid #ddd;
                        margin: 0 auto 10px auto;
                        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
                    '>
                    </div>
                    <div style='font-size: 12px; font-weight: bold; margin-top: 5px;'>{color_str}</div>
                    <div style='font-size: 10px; color: #666; font-family: monospace;'>{hex_color}</div>
                </div>
                """, unsafe_allow_html=True)

            except Exception as e:
                st.error(f"é¢œè‰²è§£æé”™è¯¯: {color_str}")
                continue

    # é¢å¤–æ˜¾ç¤ºè°ƒè‰²æ¿æ¡
    st.markdown("### ğŸ¨ è°ƒè‰²æ¿é¢„è§ˆ")
    palette_html = "<div style='display: flex; height: 60px; border-radius: 10px; overflow: hidden; border: 2px solid #ddd;'>"

    for color_str in colors_rgb:
        try:
            rgb_values = color_str.replace('RGB(', '').replace(')', '').split(', ')
            r, g, b = map(int, rgb_values)
            hex_color = f"#{r:02x}{g:02x}{b:02x}"
            palette_html += f"<div style='flex: 1; background-color: {hex_color};'></div>"
        except:
            continue

    palette_html += "</div>"
    st.markdown(palette_html, unsafe_allow_html=True)

def parse_generated_colors(generated_plan: str) -> List[str]:
    """ä»ç”Ÿæˆçš„æ–¹æ¡ˆä¸­æå–RGBé¢œè‰²"""
    import re
    rgb_pattern = r'RGB\s*\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\)'
    matches = re.findall(rgb_pattern, generated_plan)

    colors = []
    for match in matches:
        r, g, b = map(int, match)
        colors.append(f"RGB({r}, {g}, {b})")

    return colors

def main():
    """ä¸»åº”ç”¨å‡½æ•°"""

    # ä¸»æ ‡é¢˜
    st.markdown('<h1 class="main-header">ColorRAG</h1>', unsafe_allow_html=True)
    st.markdown('<p class="subtitle">ä¸“ä¸šçº§æ™ºèƒ½é…è‰²è®¾è®¡å¹³å°ï¼Œè®©æ¯ä¸ªäººéƒ½èƒ½æˆä¸ºè‰²å½©ä¸“å®¶</p>', unsafe_allow_html=True)

    # ä»·å€¼ä¸»å¼ 
    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""
        <div class="feature-card">
            <div style="text-align: center;">
                <div style="font-size: 3rem; margin-bottom: 1rem;">ğŸ¨</div>
                <h3 style="color: #333; margin-bottom: 1rem;">ä¸“ä¸šé…è‰²</h3>
                <p style="color: #666; line-height: 1.6;">åŸºäºè‰²å½©ç†è®ºå’Œè®¾è®¡ç¾å­¦ï¼Œä¸ºæ‚¨æä¾›ä¸“ä¸šçº§çš„é…è‰²æ–¹æ¡ˆ</p>
            </div>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div class="feature-card">
            <div style="text-align: center;">
                <div style="font-size: 3rem; margin-bottom: 1rem;">âš¡</div>
                <h3 style="color: #333; margin-bottom: 1rem;">ç§’é€Ÿç”Ÿæˆ</h3>
                <p style="color: #666; line-height: 1.6;">ä¸Šä¼ å›¾ç‰‡ï¼Œæè¿°éœ€æ±‚ï¼ŒAIç¬é—´ä¸ºæ‚¨ç”Ÿæˆå¤šå¥—ç²¾ç¾é…è‰²æ–¹æ¡ˆ</p>
            </div>
        </div>
        """, unsafe_allow_html=True)

    with col3:
        st.markdown("""
        <div class="feature-card">
            <div style="text-align: center;">
                <div style="font-size: 3rem; margin-bottom: 1rem;">ğŸ’</div>
                <h3 style="color: #333; margin-bottom: 1rem;">å¤šæ ·é€‰æ‹©</h3>
                <p style="color: #666; line-height: 1.6;">ä¸€æ¬¡ç”Ÿæˆä¸‰å¥—ä¸åŒé£æ ¼çš„æ–¹æ¡ˆï¼Œæ€»æœ‰ä¸€æ¬¾é€‚åˆæ‚¨çš„éœ€æ±‚</p>
            </div>
        </div>
        """, unsafe_allow_html=True)

    # åå°åŠ è½½æ¨¡å‹ï¼ˆä¸æ˜¾ç¤ºç»™ç”¨æˆ·ï¼‰
    with st.spinner("ğŸš€ AIå¤§å¸ˆæ­£åœ¨å‡†å¤‡ä¸­..."):
        model, theta, knowledge_base, architecture = load_models()

    if model is None:
        st.error("ğŸ˜” AIå¤§å¸ˆæš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•")
        return

    # è®¾ç½®é»˜è®¤å‚æ•°ï¼ˆä¸è®©ç”¨æˆ·çœ‹åˆ°æŠ€æœ¯ç»†èŠ‚ï¼‰
    text_top_k = 10
    final_top_k = 3

    # é£æ ¼æŒ‡å¯¼åŒºåŸŸ
    st.markdown("---")
    st.markdown("## ğŸ¨ é…è‰²é£æ ¼æŒ‡å¯¼")

    # é£æ ¼æŒ‡å¯¼å¡ç‰‡
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        <div class="feature-card">
            <h4 style="color: #333; margin-bottom: 1rem;">ğŸŒˆ è‰²å½©é£æ ¼è¯æ±‡</h4>
            <div style="line-height: 2;">
                <span style="background: #f0f8ff; padding: 4px 8px; border-radius: 15px; margin: 2px; display: inline-block; font-size: 0.9rem;">ç°ä»£ç®€çº¦</span>
                <span style="background: #fff5ee; padding: 4px 8px; border-radius: 15px; margin: 2px; display: inline-block; font-size: 0.9rem;">æ¸©é¦¨èˆ’é€‚</span>
                <span style="background: #f0fff0; padding: 4px 8px; border-radius: 15px; margin: 2px; display: inline-block; font-size: 0.9rem;">æ¸…æ–°è‡ªç„¶</span>
                <span style="background: #fdf5e6; padding: 4px 8px; border-radius: 15px; margin: 2px; display: inline-block; font-size: 0.9rem;">å¤å¤æ€€æ—§</span>
                <span style="background: #f5f5dc; padding: 4px 8px; border-radius: 15px; margin: 2px; display: inline-block; font-size: 0.9rem;">å¥¢åå…¸é›…</span>
                <span style="background: #e6e6fa; padding: 4px 8px; border-radius: 15px; margin: 2px; display: inline-block; font-size: 0.9rem;">æ´»åŠ›åŠ¨æ„Ÿ</span>
                <span style="background: #ffe4e1; padding: 4px 8px; border-radius: 15px; margin: 2px; display: inline-block; font-size: 0.9rem;">æµªæ¼«æŸ”ç¾</span>
                <span style="background: #f0f0f0; padding: 4px 8px; border-radius: 15px; margin: 2px; display: inline-block; font-size: 0.9rem;">å·¥ä¸šé£æ ¼</span>
            </div>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div class="feature-card">
            <h4 style="color: #333; margin-bottom: 1rem;">ğŸ’¡ æè¿°å»ºè®®</h4>
            <ul style="color: #666; line-height: 1.8;">
                <li><strong>ç©ºé—´ç±»å‹ï¼š</strong>åŠå…¬å®¤ã€å’–å•¡å…ã€å§å®¤ã€å®¢å…ç­‰</li>
                <li><strong>æœŸæœ›æ°›å›´ï¼š</strong>ä¸“ä¸šã€æ¸©é¦¨ã€æ´»åŠ›ã€å®é™ç­‰</li>
                <li><strong>è‰²å½©åå¥½ï¼š</strong>æš–è‰²è°ƒã€å†·è‰²è°ƒã€ä¸­æ€§è‰²ç­‰</li>
                <li><strong>ä½¿ç”¨åœºæ™¯ï¼š</strong>å·¥ä½œã€ä¼‘æ¯ã€å¨±ä¹ã€å•†åŠ¡ç­‰</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

    # è¾“å…¥åŒºåŸŸ - å¹¶æ’å¸ƒå±€
    st.markdown("---")
    st.markdown("## ğŸ“ å¼€å§‹åˆ›ä½œæ‚¨çš„ä¸“å±é…è‰²")

    col1, col2 = st.columns([1, 1])

    with col1:
        st.markdown("### ğŸ¯ æè¿°æ‚¨çš„è®¾è®¡éœ€æ±‚")
        user_text = st.text_area(
            "",
            placeholder="ä¾‹å¦‚ï¼šæˆ‘æƒ³ä¸ºæˆ‘çš„å’–å•¡å…è®¾è®¡ä¸€å¥—æ¸©é¦¨èˆ’é€‚çš„é…è‰²æ–¹æ¡ˆï¼Œå¸Œæœ›è¥é€ å‡ºæ¸…æ–°è‡ªç„¶çš„ä¼‘é—²æ°›å›´ï¼Œè®©é¡¾å®¢æ„Ÿåˆ°æ”¾æ¾æ„‰æ‚¦...",
            height=150,
            label_visibility="collapsed"
        )

        # é…è‰²æŒ‡å¯¼å’Œæè¿°å»ºè®®
        st.markdown("### ğŸ’¡ é…è‰²æŒ‡å¯¼")
        st.info("""
        **æè¿°å»ºè®®ï¼š**
        - æ˜ç¡®ä½¿ç”¨åœºæ™¯ï¼ˆå¦‚ï¼šç½‘ç«™ã€APPã€å®¤å†…è®¾è®¡ã€å“ç‰Œç­‰ï¼‰
        - æè¿°æœŸæœ›çš„æƒ…æ„Ÿæ°›å›´ï¼ˆå¦‚ï¼šæ¸©é¦¨ã€ä¸“ä¸šã€æ´»åŠ›ã€ä¼˜é›…ç­‰ï¼‰
        - æåŠç›®æ ‡ç”¨æˆ·ç¾¤ä½“ï¼ˆå¦‚ï¼šå¹´è½»äººã€å•†åŠ¡äººå£«ã€å®¶åº­ç­‰ï¼‰
        - è¯´æ˜åŠŸèƒ½éœ€æ±‚ï¼ˆå¦‚ï¼šæ˜“è¯»æ€§ã€æ³¨æ„åŠ›å¼•å¯¼ç­‰ï¼‰

        **å¸¸è§åœºæ™¯å‚è€ƒï¼š**
        ç°ä»£ç®€çº¦åŠå…¬ç©ºé—´ | æ¸©é¦¨å®¶å±…å®¢å… | é«˜ç«¯é…’åº—å¤§å ‚ | æ¸…æ–°å’–å•¡åº— | ç§‘æŠ€APPç•Œé¢ | ä¼˜é›…ä¹¦åº— | æ´»åŠ›å¥èº«æˆ¿ | å®é™ç‘œä¼½é¦†
        """)

    with col2:
        st.markdown("### ğŸ–¼ï¸ ä¸Šä¼ çµæ„Ÿå›¾ç‰‡")
        uploaded_image = st.file_uploader(
            "",
            type=['png', 'jpg', 'jpeg', 'webp'],
            help="ä¸Šä¼ èƒ½ä½“ç°æ‚¨æœŸæœ›é£æ ¼çš„å›¾ç‰‡ï¼ŒAIå°†åˆ†æå…¶è‰²å½©ç‰¹ç‚¹",
            label_visibility="collapsed"
        )

        if uploaded_image is not None:
            image = Image.open(uploaded_image)
            # é™åˆ¶å›¾ç‰‡æ˜¾ç¤ºå®½åº¦ï¼Œå‡å°‘ç©ºç™½åŒºåŸŸ
            st.image(image, caption="âœ¨ æ‚¨çš„çµæ„Ÿå›¾ç‰‡", width=300)
        else:
            st.info("ğŸ“· è¯·ä¸Šä¼ ä¸€å¼ å›¾ç‰‡ä½œä¸ºé…è‰²çµæ„Ÿæ¥æº")

    # ç”ŸæˆæŒ‰é’®
    st.markdown("---")
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("ğŸ¨ ç«‹å³ç”Ÿæˆæˆ‘çš„ä¸“å±é…è‰²", type="primary", use_container_width=True):
            if not user_text.strip():
                st.warning("ğŸ’­ è¯·å…ˆæè¿°æ‚¨çš„è®¾è®¡éœ€æ±‚")
                return

            if uploaded_image is None:
                st.warning("ğŸ“¸ è¯·ä¸Šä¼ ä¸€å¼ çµæ„Ÿå›¾ç‰‡")
                return

            # å¼€å§‹ç”Ÿæˆæµç¨‹ï¼ˆéšè—è¿‡ç¨‹ï¼‰
            generate_color_scheme(
                user_text, uploaded_image, model, theta, knowledge_base,
                text_top_k, final_top_k
            )

def generate_color_scheme(user_text: str, uploaded_image, model, theta, knowledge_base,
                         text_top_k: int, final_top_k: int):
    """ç”Ÿæˆé…è‰²æ–¹æ¡ˆçš„å®Œæ•´æµç¨‹"""

    # æ˜¾ç¤ºåŠ è½½çŠ¶æ€
    with st.spinner("ğŸ¨ AIå¤§å¸ˆæ­£åœ¨ä¸ºæ‚¨ç²¾å¿ƒåˆ›ä½œé…è‰²æ–¹æ¡ˆ..."):
        try:
            # åå°å¤„ç†ï¼Œä¸æ˜¾ç¤ºå…·ä½“æ­¥éª¤
            fused_text, image_description = image_understanding(uploaded_image, user_text)

            text_matrix, color_matrix, selected_idx = topic_model_inference(model, theta, fused_text)

            if text_matrix is None:
                st.error("ğŸ˜” AIå¤§å¸ˆé‡åˆ°äº†ä¸€äº›å›°éš¾ï¼Œè¯·é‡è¯•")
                return

            top_results, max_text_sim, max_color_sim = similarity_retrieval(
                text_matrix, color_matrix, knowledge_base, text_top_k, final_top_k
            )

            generated_plans = deepseek_generation_multiple(text_matrix, color_matrix, top_results, user_text, image_description)

            # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
            st.markdown("---")
            st.markdown("## ğŸ‰ æ‚¨çš„ä¸“å±é…è‰²æ–¹æ¡ˆ")
            st.markdown("### AIå¤§å¸ˆä¸ºæ‚¨ç²¾å¿ƒè®¾è®¡äº†3å¥—ä¸åŒé£æ ¼çš„é…è‰²æ–¹æ¡ˆï¼Œè¯·é€‰æ‹©æ‚¨æœ€å–œæ¬¢çš„ä¸€å¥—ï¼š")

            if generated_plans and len(generated_plans) > 0:
                # åˆ›å»ºç¾è§‚çš„æ–¹æ¡ˆå±•ç¤º
                style_names = ["ğŸŒŸ ç»å…¸ä¼˜é›…", "ğŸ’« ç°ä»£æ—¶å°š", "âœ¨ åˆ›æ„ä¸ªæ€§"]
                tabs = st.tabs(style_names)

                for i, (tab, plan) in enumerate(zip(tabs, generated_plans)):
                    with tab:
                        # è§£æå½“å‰æ–¹æ¡ˆçš„é¢œè‰²
                        plan_colors = parse_generated_colors(plan["content"])

                        # æ˜¾ç¤ºé¢œè‰²è°ƒè‰²æ¿
                        if plan_colors:
                            st.markdown('<div class="color-palette">', unsafe_allow_html=True)
                            display_color_palette(plan_colors, f"")
                            st.markdown('</div>', unsafe_allow_html=True)

                        # æ˜¾ç¤ºæ–¹æ¡ˆè¯¦æƒ…
                        st.markdown('<div class="result-card">', unsafe_allow_html=True)

                        # ç¾åŒ–æ–¹æ¡ˆå†…å®¹æ˜¾ç¤º
                        content = plan["content"]
                        # ç§»é™¤æŠ€æœ¯æ€§æ ‡é¢˜ï¼Œä½¿ç”¨æ›´å‹å¥½çš„è¡¨è¿°
                        content = content.replace("**è®¾è®¡ç†å¿µ**", "### ğŸ’¡ è®¾è®¡ç†å¿µ")
                        content = content.replace("**é…è‰²æ–¹æ¡ˆ**", "### ğŸ¨ é…è‰²è¯¦æƒ…")
                        content = content.replace("**åº”ç”¨å»ºè®®**", "### ğŸ’¼ ä½¿ç”¨å»ºè®®")

                        st.markdown(content)
                        st.markdown('</div>', unsafe_allow_html=True)

                        # æ·»åŠ ä¸‹è½½æŒ‰é’®
                        col1, col2, col3 = st.columns([1, 1, 1])
                        with col2:
                            if st.button(f"ğŸ’¾ ä¿å­˜æ–¹æ¡ˆ{i+1}", key=f"save_{i}", use_container_width=True):
                                st.info(f"ğŸ’¾ æ–¹æ¡ˆ{i+1}å·²ä¿å­˜")
            else:
                st.error("ğŸ˜” AIå¤§å¸ˆæš‚æ—¶æ— æ³•ä¸ºæ‚¨ç”Ÿæˆæ–¹æ¡ˆï¼Œè¯·ç¨åé‡è¯•")

            # æ·»åŠ åˆ†äº«åŠŸèƒ½
            st.markdown("---")
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                if st.button("ğŸ“¤ åˆ†äº«æˆ‘çš„é…è‰²æ–¹æ¡ˆ", use_container_width=True):
                    save_results(user_text, fused_text, generated_plans, top_results)
                    st.balloons()
                    st.success("ğŸ‰ æ‚¨çš„é…è‰²æ–¹æ¡ˆå·²ä¿å­˜ï¼å¯ä»¥åˆ†äº«ç»™æœ‹å‹äº†")

        except Exception as e:
            st.error(f"ğŸ˜” AIå¤§å¸ˆé‡åˆ°äº†ä¸€äº›å›°éš¾: {str(e)}")
            st.info("ğŸ’¡ è¯·å°è¯•é‡æ–°ä¸Šä¼ å›¾ç‰‡æˆ–è°ƒæ•´éœ€æ±‚æè¿°")

def add_footer():
    """æ·»åŠ é¡µè„š"""
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; padding: 2rem; background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%); border-radius: 15px; margin-top: 3rem;'>
        <h3 style='color: #333; margin-bottom: 1rem;'>ğŸ¨ AIè‰²å½©å¤§å¸ˆ</h3>
        <p style='color: #666; margin-bottom: 1rem;'>è®©æ¯ä¸ªäººéƒ½èƒ½æˆä¸ºè‰²å½©ä¸“å®¶</p>
        <div style='display: flex; justify-content: center; gap: 2rem; margin-top: 1rem;'>
            <span style='color: #888;'>âœ¨ ä¸“ä¸šé…è‰²</span>
            <span style='color: #888;'>âš¡ ç§’é€Ÿç”Ÿæˆ</span>
            <span style='color: #888;'>ğŸ’ å¤šæ ·é€‰æ‹©</span>
        </div>
        <p style='color: #999; font-size: 0.9rem; margin-top: 1rem;'>Â© 2024 AIè‰²å½©å¤§å¸ˆ - æ™ºèƒ½é…è‰²è®¾è®¡å¹³å°</p>
    </div>
    """, unsafe_allow_html=True)

def save_results(user_text: str, fused_text: str, generated_plans: List[Dict], top_results: List[Dict]):
    """ä¿å­˜ç”Ÿæˆç»“æœ"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    result_data = {
        "timestamp": timestamp,
        "user_input": user_text,
        "fused_text": fused_text,
        "generated_plans": generated_plans,
        "top_results": top_results
    }

    filename = f"streamlit_results_{timestamp}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    main()
    add_footer()
